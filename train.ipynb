{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3d7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "# 导入项目中的模块\n",
    "from models import SimpleMLP, DeepMLP, ResidualMLP, SimpleCNN, MediumCNN, VGGStyleNet, SimpleResNet\n",
    "from utils import (\n",
    "    load_cifar10,\n",
    "    set_seed,\n",
    "    train_model,\n",
    "    evaluate_model,\n",
    "    plot_training_history,\n",
    "    visualize_model_predictions,\n",
    "    visualize_conv_filters,\n",
    "    model_complexity\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8a2cb3",
   "metadata": {
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "训练集大小: 45000\n",
      "验证集大小: 5000\n",
      "测试集大小: 10000\n",
      "使用模型: SimpleMLP\n"
     ]
    }
   ],
   "source": [
    "# 设置参数\n",
    "model_type = 'simple_mlp'  # 可选: 'simple_mlp', 'deep_mlp', 'residual_mlp', 'simple_cnn', 'medium_cnn', 'vgg_style', 'resnet'\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "use_data_augmentation = True  # CNN通常受益于数据增强\n",
    "save_directory = './ck'\n",
    "visualize_filters = True  # 是否可视化卷积核（仅对CNN有效）\n",
    "visualize_predictions = True  # 是否可视化预测结果\n",
    "\n",
    "# 设置随机种子\n",
    "set_seed()\n",
    "\n",
    "#因为mo平台的提交任务机制，需要手动切换到该文件夹下。\n",
    "# os.chdir(os.path.expanduser(\"~/work/Jianhai/lab5\"))\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 加载数据\n",
    "train_loader, valid_loader, test_loader, classes = load_cifar10(\n",
    "    use_augmentation=use_data_augmentation,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# 初始化选择的模型\n",
    "if model_type == 'simple_mlp':\n",
    "    model = SimpleMLP()\n",
    "    model_name = \"SimpleMLP\"\n",
    "elif model_type == 'deep_mlp':\n",
    "    model = DeepMLP(dropout_rate=0.5, use_bn=True, use_dropout=True)\n",
    "    model_name = \"DeepMLP\"\n",
    "elif model_type == 'residual_mlp':\n",
    "    model = ResidualMLP(activation='relu')\n",
    "    model_name = \"ResidualMLP\"\n",
    "elif model_type == 'simple_cnn':\n",
    "    model = SimpleCNN()\n",
    "    model_name = \"SimpleCNN\"\n",
    "elif model_type == 'medium_cnn':\n",
    "    model = MediumCNN(use_bn=True)\n",
    "    model_name = \"MediumCNN\"\n",
    "elif model_type == 'vgg_style':\n",
    "    model = VGGStyleNet()\n",
    "    model_name = \"VGGStyleNet\"\n",
    "else:  # resnet\n",
    "    model = SimpleResNet(num_blocks=[2, 2, 2])\n",
    "    model_name = \"SimpleResNet\"\n",
    "\n",
    "print(f\"使用模型: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f4362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "分析模型复杂度:\n",
      "参数量: 1,578,506\n",
      "每批次(128个样本)推理时间: 4.66ms\n",
      "Epoch 1/20\n",
      "模型已保存到 ./ck/SimpleMLP_best.pth\n",
      "训练损失: 1.8822, 训练准确率: 0.3409\n",
      "验证损失: 1.7394, 验证准确率: 0.3826\n",
      "本轮用时: 29.98s\n",
      "--------------------------------------------------\n",
      "Epoch 2/20\n",
      "模型已保存到 ./ck/SimpleMLP_best.pth\n",
      "训练损失: 1.7017, 训练准确率: 0.3987\n",
      "验证损失: 1.6885, 验证准确率: 0.4068\n",
      "本轮用时: 35.59s\n",
      "--------------------------------------------------\n",
      "Epoch 3/20\n",
      "模型已保存到 ./ck/SimpleMLP_best.pth\n",
      "训练损失: 1.6431, 训练准确率: 0.4195\n",
      "验证损失: 1.6237, 验证准确率: 0.4230\n",
      "本轮用时: 37.59s\n",
      "--------------------------------------------------\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m os.makedirs(save_directory, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m trained_model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_directory\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 绘制训练历史\u001b[39;00m\n\u001b[32m     22\u001b[39m plot_training_history(history, title=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Training History\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\zju_course\\ai_basic\\lab\\lab5\\lab5\\utils\\train_utils.py:54\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs, device, save_dir)\u001b[39m\n\u001b[32m     51\u001b[39m train_correct = \u001b[32m0\u001b[39m\n\u001b[32m     52\u001b[39m train_total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 梯度清零\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:491\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:422\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    421\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1139\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1144\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1145\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1148\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\context.py:337\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     94\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     97\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20911\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 计算模型复杂度\n",
    "print(\"\\n分析模型复杂度:\")\n",
    "model_complexity(model, device=device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 可以添加学习率调度器\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "# 确保checkpoints目录存在\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# 训练模型\n",
    "trained_model, history = train_model(\n",
    "    model, train_loader, valid_loader, criterion, optimizer, scheduler,\n",
    "    num_epochs=epochs, device=device, save_dir=save_directory\n",
    ")\n",
    "\n",
    "# 绘制训练历史\n",
    "plot_training_history(history, title=f\"{model_name} Training History\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "print(\"\\n在测试集上评估模型:\")\n",
    "test_loss, test_acc = evaluate_model(trained_model, test_loader, criterion, device, classes)\n",
    "\n",
    "print(f\"{model_name} 最终测试准确率: {test_acc:.4f}\")\n",
    "\n",
    "# 如果是CNN模型并且需要可视化卷积核\n",
    "if visualize_filters and model_type in ['simple_cnn', 'medium_cnn', 'vgg_style', 'resnet']:\n",
    "    print(\"\\n可视化卷积核:\")\n",
    "    if model_type == 'simple_cnn':\n",
    "        visualize_conv_filters(trained_model, 'conv1')\n",
    "    elif model_type == 'medium_cnn':\n",
    "        visualize_conv_filters(trained_model, 'conv1')\n",
    "    elif model_type == 'vgg_style':\n",
    "        visualize_conv_filters(trained_model, 'features.0')\n",
    "    else:  # resnet\n",
    "        visualize_conv_filters(trained_model, 'conv1')\n",
    "\n",
    "# 如果需要可视化模型预测\n",
    "if visualize_predictions:\n",
    "    print(\"\\n可视化模型预测:\")\n",
    "    visualize_model_predictions(trained_model, test_loader, classes, device)\n",
    "\n",
    "print(f\"\\n{model_name}的训练和评估已完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9379a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f08d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
